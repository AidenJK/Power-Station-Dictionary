# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03-page-population.ipynb (unless otherwise specified).

__all__ = ['get_dp_field_to_url_format_str', 'format_id_values', 'single_site_data_to_ids_df',
           'single_site_data_to_ids_md_str', 'get_datapackage_url_to_alt_indexes', 'get_datapackage_url_to_attributes',
           'filter_dict', 'set_multi_index_names', 'create_multi_index_attrs_df', 'get_attrs_df_index_cols',
           'create_single_index_attrs_df', 'idx_to_attr_name', 'get_field_class', 'format_attribute_value_types',
           'construct_attr_to_field_schema', 'get_datapackage_url_to_attrs_md_str', 'construct_dataset_md_str',
           'single_site_data_to_datasets_md_str', 'clean_dp_name', 'extract_name_from_single_site_data',
           'single_site_data_to_md_str', 'populate_and_save_template', 'clean_object_names']

# Cell
import json
import numpy as np
import pandas as pd
from frictionless import Package

from powerdict import extraction

import os
from tqdm import tqdm
from warnings import warn

from jinja2 import Template

# Cell
def get_dp_field_to_url_format_str(datapackage_json_fp):
    package = Package(datapackage_json_fp, profile='tabular-data-package')
    ids_resource = package.get_resource('ids')

    id_field_to_url_format_str = {
        field['name']: field['url_format']
        for field
        in ids_resource['schema']['fields']
        if 'url_format' in field.keys()
    }

    return id_field_to_url_format_str

# Cell
def format_id_values(id_values, id_type, id_field_to_url_format_str):
    if id_type in id_field_to_url_format_str.keys():
        url_format_str = id_field_to_url_format_str[id_type]
        id_values_strs = [f'[{id_value}]({url_format_str.format(value=id_value)})' for id_value in id_values]
    else:
        id_values_strs = [str(id_value) for id_value in id_values]

    return id_values_strs

# Cell
def single_site_data_to_ids_df(single_site_data, root_id, datapackage_json_fp, root_id_type='osuked_id'):
    id_field_to_url_format_str = get_dp_field_to_url_format_str(datapackage_json_fp)
    df_site_ids = pd.DataFrame([{'Relationship': 'root', 'ID Type': root_id_type, 'ID(s)': root_id}])

    hierarchy_level_to_relationship = {
        'parent': 'parent',
        'child': 'element-of',
        'equivalent': 'same-as'
    }

    for hierarchy_level, ids in single_site_data['id_hierarchies'].items():
        if len(ids) >= 1:
            ids = {
                id_type: (', '.join([str(id_) for id_ in format_id_values(id_values, id_type, id_field_to_url_format_str)]) if isinstance(id_values, list) else id_values)
                for id_type, id_values
                in ids.items()
            }

            relationship = hierarchy_level_to_relationship[hierarchy_level]

            df_site_ids = df_site_ids.append(pd
                                             .Series(ids)
                                             .reset_index()
                                             .assign(Relationship=relationship)
                                             .rename(columns={'index': 'ID Type', 0: 'ID(s)'})
                                            )

    if df_site_ids.size >= 1:
        df_site_ids = df_site_ids.set_index(['Relationship', 'ID Type'])

    return df_site_ids

def single_site_data_to_ids_md_str(single_site_data, root_id, datapackage_json_fp):
    df_site_ids = single_site_data_to_ids_df(single_site_data, root_id, datapackage_json_fp)
    site_ids_md_table = df_site_ids.reset_index().to_markdown(index=False)
    site_ids_md_str = '### Identifiers\n\n' + site_ids_md_table

    return site_ids_md_str

# Cell
filter_dict = lambda dict_, keys_to_select: {k: dict_[k] for k in keys_to_select}

def get_datapackage_url_to_alt_indexes(single_site_data):
    datapackage_url_to_alt_indexes = {}

    if 'datasets' in single_site_data.keys():
        for datapackage_url, dataset_ref in single_site_data['datasets'].items():
            alt_indexes = []

            if 'alt_indexes' in dataset_ref['related_resources'][0].keys():
                alt_indexes += dataset_ref['related_resources'][0]['alt_indexes']

            datapackage_url_to_alt_indexes[datapackage_url] = alt_indexes

    return datapackage_url_to_alt_indexes

def get_datapackage_url_to_attributes(single_site_data):
    datapackage_url_to_attributes = {}

    if 'attributes' in single_site_data.keys():
        for attr in single_site_data['attributes']:
            datapackage_url = attr['source']
            attribute_values = filter_dict(attr, ['attribute', 'value', 'id'])

            if datapackage_url not in datapackage_url_to_attributes.keys():
                datapackage_url_to_attributes[datapackage_url] = []

            datapackage_url_to_attributes[datapackage_url] += [attribute_values]

    return datapackage_url_to_attributes

# Cell
get_attrs_df_index_cols = lambda df_attrs: ['attribute'] + [elem for elem in df_attrs.columns if elem not in ('attribute', 'id', 0)]

def set_multi_index_names(df, names, capitalise=True):
    if capitalise == True:
        names = [name.capitalize() for name in names]

    df.index.names = names

    return df

def create_multi_index_attrs_df(attributes, alt_indexes):
    df_attrs = (
        pd.DataFrame(attributes)
        .set_index(['attribute', 'id'])
        ['value']
        .apply(pd.Series)
        .drop_duplicates()
        .stack()
        .reset_index()
        .pipe(lambda df: df.pivot(get_attrs_df_index_cols(df), 'id', 0))
        .pipe(set_multi_index_names, ['attribute']+alt_indexes)
    )

    if df_attrs.shape[1] == 1:
        df_attrs.columns.name = ''
        df_attrs.columns = ['Value']

    return df_attrs

# Cell
def create_single_index_attrs_df(attributes):
    df_attrs = pd.DataFrame(attributes)

    if df_attrs['id'].unique().size > 1:
        df_attrs = df_attrs.pivot('attribute', 'id', 'value')
    else:
        df_attrs = df_attrs.set_index('attribute').drop(columns='id')
        df_attrs = df_attrs.rename(columns={'value': 'Value'})

    df_attrs.index.name = df_attrs.index.name.capitalize()

    return df_attrs

# Cell
from frictionless.types.array import type_to_class
from frictionless.field import Field

construct_attr_to_field_schema = lambda single_site_data: {attr['attribute']: attr['field_schema'] for attr in single_site_data['attributes']}

def idx_to_attr_name(idx):
    if isinstance(idx, tuple):
        attr = idx[0]
    else:
        attr = idx

    return attr

def get_field_class(attr, attr_to_field_schema):
    field_schema = Field(attr_to_field_schema[attr])
    field_type = field_schema['type']
    field_class = type_to_class[field_type](field_schema)

    return field_class

def format_attribute_value_types(df_attributes, attr_to_field_schema):
    for idx, row in df_attributes.iterrows():
        attr = idx_to_attr_name(idx)
        field_class = get_field_class(attr, attr_to_field_schema)

        for id_, value in row.items():
            df_attributes.loc[idx, id_] = field_class.read_cell(value)

    return df_attributes

# Cell
def get_datapackage_url_to_attrs_md_str(single_site_data):
    attr_to_field_schema = construct_attr_to_field_schema(single_site_data)
    datapackage_url_to_alt_indexes = get_datapackage_url_to_alt_indexes(single_site_data)
    datapackage_url_to_attrs = get_datapackage_url_to_attributes(single_site_data)

    datapackage_url_to_md_str = {}

    for datapackage_url, attributes in datapackage_url_to_attrs.items():
        alt_indexes = datapackage_url_to_alt_indexes[datapackage_url]

        if len(alt_indexes) > 0:
            df_attrs = create_multi_index_attrs_df(attributes, alt_indexes)
        else:
            df_attrs = create_single_index_attrs_df(attributes)

        df_attrs = format_attribute_value_types(df_attrs, attr_to_field_schema)

        datapackage_url_to_md_str[datapackage_url] = (
            df_attrs

            .reset_index()
            .astype(str)
            .to_markdown(index=False, floatfmt='.2f')
        )

    return datapackage_url_to_md_str

# Cell
clean_dp_name = lambda dp_name: dp_name.replace('-', ' ').title()

def construct_dataset_md_str(dataset_metadata, dataset_attributes):
    title = clean_dp_name(dataset_metadata['datapackage_name'])
    url = dataset_metadata['datapackage_json_url']
    description = dataset_metadata['datapackage_description']
    dictionary_column_match = dataset_metadata['related_resources'][0]['dictionary_pk_field']
    dataset_column_match = dataset_metadata['related_resources'][0]['external_fk_field']

    dataset_str = f"""##### <a href="{url}">{title}</a>

{description}

The \"{dictionary_column_match}\" field was used to match from the dictionary to the \"{dataset_column_match}\" field in this dataset.

{dataset_attributes}\n"""

    return dataset_str

def single_site_data_to_datasets_md_str(single_site_data):
    datapackage_url_to_attrs_md_str = get_datapackage_url_to_attrs_md_str(single_site_data)
    dataset_url_to_md_str = {}

    for dataset_metadata in single_site_data['datasets'].values():
        dataset_url = dataset_metadata['datapackage_json_url']
        dataset_attributes = datapackage_url_to_attrs_md_str[dataset_url]
        dataset_str = construct_dataset_md_str(dataset_metadata, dataset_attributes)

        dataset_url_to_md_str[dataset_url] = dataset_str

    datasets_md_str = '### Datasets\n' + '\n<br><br>\n'.join(list(dataset_url_to_md_str.values()))

    return datasets_md_str

# Cell
def extract_name_from_single_site_data(single_site_data):
    potential_names = [v['name'] for k, v in single_site_data['id_hierarchies'].items() if'name' in v.keys()]

    if len(potential_names) > 0:
        name = potential_names[0]
        return name
    else:
        return None

def single_site_data_to_md_str(single_site_data, root_id, datapackage_json_fp):
    site_ids_md_str = single_site_data_to_ids_md_str(single_site_data, root_id, datapackage_json_fp)
    datasets_md_str = single_site_data_to_datasets_md_str(single_site_data)

    site_md_str = site_ids_md_str + '\n\n<br>\n' + datasets_md_str

    return site_md_str

def populate_and_save_template(template_fp, save_fp, render_kwargs):
    rendered_str = Template(open(template_fp).read()).render(**render_kwargs)

    with open(save_fp, 'w', encoding='utf-8') as f:
        try:
            f.write(rendered_str)
        except e as exc:
            raise exc

    return None

def clean_object_names(object_names):
    object_names = sorted(object_names)

    alpha_names = [name for name in object_names if name[0].isalpha()]
    numeric_names = [name for name in object_names if not name[0].isalpha()]

    object_names = alpha_names + numeric_names

    return object_names