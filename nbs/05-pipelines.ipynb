{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "<br>\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "from powerdict import download, construct, update\n",
    "\n",
    "import os\n",
    "from typing import Any\n",
    "\n",
    "from dagster import execute_pipeline, pipeline, solid, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### End-to-End Dataset Generation\n",
    "\n",
    "We're now going to combine the dictionary generation steps into a pipeline using dagster, first we'll create the individual components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "@solid()\n",
    "def download_source_data(context, raw_data_dir: str):\n",
    "    try:\n",
    "        download.download_opsd_power_plants_data(raw_data_dir)\n",
    "        context.log.info('The latest source data was successfully retrieved')\n",
    "    except:\n",
    "        context.log.info('Source data could not be updated, will proceed with existing raw data sources')\n",
    "    \n",
    "    return \n",
    "\n",
    "@solid()\n",
    "def construct_intermediate_dataset(_, definitions_dir: str, raw_data_dir: str, intermediate_data_dir: str) -> Any:\n",
    "    df = construct.construct_output_df(definitions_dir, raw_data_dir)\n",
    "    df.to_csv(f'{intermediate_data_dir}/power_stations.csv')\n",
    "    \n",
    "    return df\n",
    "\n",
    "@solid()\n",
    "def update_dataset_updates(_, df: Any, updates_data_dir: str) -> Any:\n",
    "    df = update.apply_updates(df, updates_data_dir)\n",
    "    \n",
    "    return df\n",
    "\n",
    "@solid()\n",
    "def clean_output_dataset(_, df: Any, definitions_dir: str) -> Any:\n",
    "    df = update.check_and_apply_output_defs(df, definitions_dir)\n",
    "    \n",
    "    return df\n",
    "\n",
    "@solid()\n",
    "def save_output_dataset(_, df: Any, output_data_dir: str):\n",
    "    if not os.path.exists(output_data_dir):\n",
    "        os.makedirs(output_data_dir)\n",
    "        \n",
    "    df.to_csv(f'{output_data_dir}/power_stations.csv')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Then we'll combine them in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "@pipeline\n",
    "def generate_output_dataset_pipeline():  \n",
    "    download_source_data()\n",
    "    \n",
    "    df = construct_intermediate_dataset()\n",
    "    df = update_dataset_updates(df)\n",
    "    df = clean_output_dataset(df)\n",
    "    \n",
    "    save_output_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Which we can then run with `execute_pipeline` whilst also specifying the run_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-07-06 09:06:27\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - ENGINE_EVENT - Starting initialization of resources [asset_store].\n",
      "\u001b[32m2021-07-06 09:06:27\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - ENGINE_EVENT - Finished initialization of resources [asset_store].\n",
      "\u001b[32m2021-07-06 09:06:27\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - PIPELINE_START - Started execution of pipeline \"generate_output_dataset_pipeline\".\n",
      "\u001b[32m2021-07-06 09:06:27\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - ENGINE_EVENT - Executing steps in process (pid: 8424)\n",
      "\u001b[32m2021-07-06 09:06:27\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - construct_intermediate_dataset.compute - STEP_START - Started execution of step \"construct_intermediate_dataset.compute\".\n",
      "\u001b[32m2021-07-06 09:06:27\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - construct_intermediate_dataset.compute - STEP_INPUT - Got input \"definitions_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:27\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - construct_intermediate_dataset.compute - STEP_INPUT - Got input \"raw_data_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:27\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - construct_intermediate_dataset.compute - STEP_INPUT - Got input \"intermediate_data_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:28\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - construct_intermediate_dataset.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:28\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - construct_intermediate_dataset.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "\u001b[32m2021-07-06 09:06:28\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - construct_intermediate_dataset.compute - STEP_SUCCESS - Finished execution of step \"construct_intermediate_dataset.compute\" in 643ms.\n",
      "\u001b[32m2021-07-06 09:06:28\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - download_source_data.compute - STEP_START - Started execution of step \"download_source_data.compute\".\n",
      "\u001b[32m2021-07-06 09:06:28\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - download_source_data.compute - STEP_INPUT - Got input \"raw_data_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mINFO\u001b[0m - system - 12c39666-77ee-4296-8f76-28716b97c61a - download_source_data.compute - The latest source data was successfully retrieved\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - download_source_data.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - download_source_data.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - download_source_data.compute - STEP_SUCCESS - Finished execution of step \"download_source_data.compute\" in 973ms.\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - update_dataset_updates.compute - STEP_START - Started execution of step \"update_dataset_updates.compute\".\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - update_dataset_updates.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df in memory object store using pickle.\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - update_dataset_updates.compute - STEP_INPUT - Got input \"df\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - update_dataset_updates.compute - STEP_INPUT - Got input \"updates_data_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - update_dataset_updates.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - update_dataset_updates.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - update_dataset_updates.compute - STEP_SUCCESS - Finished execution of step \"update_dataset_updates.compute\" in 14ms.\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - clean_output_dataset.compute - STEP_START - Started execution of step \"clean_output_dataset.compute\".\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - clean_output_dataset.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df in memory object store using pickle.\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - clean_output_dataset.compute - STEP_INPUT - Got input \"df\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - clean_output_dataset.compute - STEP_INPUT - Got input \"definitions_dir\" of type \"String\". (Type check passed).\n",
      "c:\\users\\ayrto\\desktop\\side projects\\power-station-dictionary\\powerdict\\update.py:76: UserWarning: plant_type was not found in the output dataset\n",
      "  warn(f'{output_col} was not found in the output dataset')\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - clean_output_dataset.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - clean_output_dataset.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - clean_output_dataset.compute - STEP_SUCCESS - Finished execution of step \"clean_output_dataset.compute\" in 10ms.\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - save_output_dataset.compute - STEP_START - Started execution of step \"save_output_dataset.compute\".\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - save_output_dataset.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df in memory object store using pickle.\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - save_output_dataset.compute - STEP_INPUT - Got input \"df\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - save_output_dataset.compute - STEP_INPUT - Got input \"output_data_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - save_output_dataset.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - save_output_dataset.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - save_output_dataset.compute - STEP_SUCCESS - Finished execution of step \"save_output_dataset.compute\" in 9.4ms.\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - ENGINE_EVENT - Finished steps in process (pid: 8424) in 1.7s\n",
      "\u001b[32m2021-07-06 09:06:29\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - 12c39666-77ee-4296-8f76-28716b97c61a - 8424 - PIPELINE_SUCCESS - Finished execution of pipeline \"generate_output_dataset_pipeline\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dagster.core.execution.results.PipelineExecutionResult at 0x21834141970>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_config = {\n",
    "    'solids': {\n",
    "        'download_source_data': {\n",
    "            'inputs': {\n",
    "                'raw_data_dir': '../data/raw'\n",
    "            },\n",
    "        },\n",
    "        'construct_intermediate_dataset': {\n",
    "            'inputs': {\n",
    "                'definitions_dir': '../data/definitions',\n",
    "                'raw_data_dir': '../data/raw',\n",
    "                'intermediate_data_dir': '../data/intermediate'\n",
    "            },\n",
    "        },\n",
    "        'update_dataset_updates': {\n",
    "            'inputs': {\n",
    "                'updates_data_dir': '../data/updates'\n",
    "            },\n",
    "        },\n",
    "        'clean_output_dataset': {\n",
    "            'inputs': {\n",
    "                'definitions_dir': '../data/definitions'\n",
    "            },\n",
    "        },\n",
    "        'save_output_dataset': {\n",
    "            'inputs': {\n",
    "                'output_data_dir': '../data/output'\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "execute_pipeline(generate_output_dataset_pipeline, run_config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PowerDict",
   "language": "python",
   "name": "powerdict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
