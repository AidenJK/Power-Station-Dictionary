{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Pipeline\n",
    "\n",
    "<br>\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "from powerdict import download, construct, update\n",
    "\n",
    "import os\n",
    "from typing import Any\n",
    "\n",
    "from dagster import execute_pipeline, pipeline, solid, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Dagster Pipeline\n",
    "\n",
    "We're now going to combine the dictionary generation steps into a pipeline using dagster, first we'll create the individual components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "@solid()\n",
    "def download_source_data(_, raw_data_dir: str):\n",
    "    download.download_opsd_power_plants_data(raw_data_dir)\n",
    "    \n",
    "    return \n",
    "\n",
    "@solid()\n",
    "def construct_intermediate_dataset(_, definitions_dir: str, raw_data_dir: str, intermediate_data_dir: str) -> Any:\n",
    "    df = construct.construct_output_df(definitions_dir, raw_data_dir)\n",
    "    df.to_csv(f'{intermediate_data_dir}/power_stations.csv')\n",
    "    \n",
    "    return df\n",
    "\n",
    "@solid()\n",
    "def update_dataset_updates(_, df: Any, updates_data_dir: str) -> Any:\n",
    "    df = update.apply_updates(df, updates_data_dir)\n",
    "    \n",
    "    return df\n",
    "\n",
    "@solid()\n",
    "def clean_output_dataset(_, df: Any, definitions_dir: str) -> Any:\n",
    "    df = update.check_and_apply_output_defs(df, definitions_dir)\n",
    "    \n",
    "    return df\n",
    "\n",
    "@solid()\n",
    "def save_output_dataset(_, df: Any, output_data_dir: str):\n",
    "    if not os.path.exists(output_data_dir):\n",
    "        os.makedirs(output_data_dir)\n",
    "        \n",
    "    df.to_csv(f'{output_data_dir}/power_stations.csv')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Then we'll combine them in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "@pipeline\n",
    "def generate_output_dataset_pipeline():  \n",
    "    download_source_data()\n",
    "    \n",
    "    df = construct_intermediate_dataset()\n",
    "    df = update_dataset_updates(df)\n",
    "    df = clean_output_dataset(df)\n",
    "    \n",
    "    save_output_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - ENGINE_EVENT - Starting initialization of resources [asset_store].\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - ENGINE_EVENT - Finished initialization of resources [asset_store].\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - PIPELINE_START - Started execution of pipeline \"generate_output_dataset_pipeline\".\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - ENGINE_EVENT - Executing steps in process (pid: 23064)\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - construct_intermediate_dataset.compute - STEP_START - Started execution of step \"construct_intermediate_dataset.compute\".\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - construct_intermediate_dataset.compute - STEP_INPUT - Got input \"definitions_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - construct_intermediate_dataset.compute - STEP_INPUT - Got input \"raw_data_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - construct_intermediate_dataset.compute - STEP_INPUT - Got input \"intermediate_data_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - construct_intermediate_dataset.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - construct_intermediate_dataset.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - construct_intermediate_dataset.compute - STEP_SUCCESS - Finished execution of step \"construct_intermediate_dataset.compute\" in 196ms.\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - download_source_data.compute - STEP_START - Started execution of step \"download_source_data.compute\".\n",
      "\u001b[32m2020-12-18 14:38:01\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - download_source_data.compute - STEP_INPUT - Got input \"raw_data_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - download_source_data.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - download_source_data.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - download_source_data.compute - STEP_SUCCESS - Finished execution of step \"download_source_data.compute\" in 1.02s.\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - update_dataset_updates.compute - STEP_START - Started execution of step \"update_dataset_updates.compute\".\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - update_dataset_updates.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df in memory object store using pickle.\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - update_dataset_updates.compute - STEP_INPUT - Got input \"df\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - update_dataset_updates.compute - STEP_INPUT - Got input \"updates_data_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - update_dataset_updates.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - update_dataset_updates.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - update_dataset_updates.compute - STEP_SUCCESS - Finished execution of step \"update_dataset_updates.compute\" in 5.94ms.\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - clean_output_dataset.compute - STEP_START - Started execution of step \"clean_output_dataset.compute\".\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - clean_output_dataset.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df in memory object store using pickle.\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - clean_output_dataset.compute - STEP_INPUT - Got input \"df\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - clean_output_dataset.compute - STEP_INPUT - Got input \"definitions_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - clean_output_dataset.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - clean_output_dataset.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - clean_output_dataset.compute - STEP_SUCCESS - Finished execution of step \"clean_output_dataset.compute\" in 4.9ms.\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - save_output_dataset.compute - STEP_START - Started execution of step \"save_output_dataset.compute\".\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - save_output_dataset.compute - OBJECT_STORE_OPERATION - Retrieved intermediate object for input df in memory object store using pickle.\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - save_output_dataset.compute - STEP_INPUT - Got input \"df\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - save_output_dataset.compute - STEP_INPUT - Got input \"output_data_dir\" of type \"String\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - save_output_dataset.compute - STEP_OUTPUT - Yielded output \"result\" of type \"Any\". (Type check passed).\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - save_output_dataset.compute - OBJECT_STORE_OPERATION - Stored intermediate object for output result in memory object store using pickle.\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - save_output_dataset.compute - STEP_SUCCESS - Finished execution of step \"save_output_dataset.compute\" in 7.25ms.\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - ENGINE_EVENT - Finished steps in process (pid: 23064) in 1.27s\n",
      "\u001b[32m2020-12-18 14:38:02\u001b[0m - dagster - \u001b[34mDEBUG\u001b[0m - generate_output_dataset_pipeline - c2197f8e-bb11-4d57-8ced-c5a3d2a9d9dd - 23064 - PIPELINE_SUCCESS - Finished execution of pipeline \"generate_output_dataset_pipeline\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dagster.core.execution.results.PipelineExecutionResult at 0x1f33bf5afd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_config = {\n",
    "    'solids': {\n",
    "        'download_source_data': {\n",
    "            'inputs': {\n",
    "                'raw_data_dir': '../data/raw'\n",
    "            },\n",
    "        },\n",
    "        'construct_intermediate_dataset': {\n",
    "            'inputs': {\n",
    "                'definitions_dir': '../data/definitions',\n",
    "                'raw_data_dir': '../data/raw',\n",
    "                'intermediate_data_dir': '../data/intermediate'\n",
    "            },\n",
    "        },\n",
    "        'update_dataset_updates': {\n",
    "            'inputs': {\n",
    "                'updates_data_dir': '../data/updates'\n",
    "            },\n",
    "        },\n",
    "        'clean_output_dataset': {\n",
    "            'inputs': {\n",
    "                'definitions_dir': '../data/definitions'\n",
    "            },\n",
    "        },\n",
    "        'save_output_dataset': {\n",
    "            'inputs': {\n",
    "                'output_data_dir': '../data/output'\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "execute_pipeline(generate_output_dataset_pipeline, run_config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01-source-data.ipynb.\n",
      "Converted 02-data-definitions.ipynb.\n",
      "Converted 03-database-construction.ipynb.\n",
      "Converted 04-updates-and-cleaning.ipynb.\n",
      "Converted 05-pipeline.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PowerDict",
   "language": "python",
   "name": "powerdict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
